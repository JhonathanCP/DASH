{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from decouple import config\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, time\n",
    "import time \n",
    "from sqlalchemy import text\n",
    "import oracledb\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo\n",
    "modelo = joblib.load('modelo_random_forest_SDC.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONEXIONES\n",
    "DB_USER=config(\"USER2_BD_SDC_POSTGRES\")\n",
    "DB_PASSWORD=config(\"PASS2_BD_SDC_POSTGRES\")\n",
    "DB_NAME=\"GCTIC_SDC\"\n",
    "DB_PORT=\"5432\"\n",
    "DB_HOST=config(\"HOST2_BD_SDC_POSTGRES\")\n",
    "cadena1  = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine1 = create_engine(cadena1)\n",
    "connection1 = engine1.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = \"citas_cext\"\n",
    "col = \"citambproconfec\"\n",
    "\n",
    "nuevos_datos = pd.read_sql_query(f\"SELECT * FROM {tabla} where {col}>='2024-05-01' and {col}<'2024-05-12 AND grupocupcod IN ('01', '02', '03', '04', '05', '21', '22', '23' ,'24','25') AND tipocitacod IN ('1', '2', '3', '4', '6')'\", con=connection1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_datos.columns = nuevos_datos.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_datos = nuevos_datos.drop(['AREHOSCOD','REDASISCOD', 'CENASICOD' , 'SERVHOSCOD','ACTCOD','GRUPOCUPCOD', 'CONDTRABCOD','TIPOCITACOD', 'CONDCITACOD', 'MODOTORCITACOD', 'ESTCITCOD'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar fechas que están fuera del rango razonable (por ejemplo, antes de 1900 y después de 2100)\n",
    "def filter_dates(date_series, min_year=1900, max_year=2100):\n",
    "    date_series = pd.to_datetime(date_series, errors='coerce')\n",
    "    return date_series[(date_series.dt.year >= min_year) & (date_series.dt.year <= max_year)]\n",
    "\n",
    "nuevos_datos['MEDNACFEC'] = filter_dates(nuevos_datos['MEDNACFEC'])\n",
    "nuevos_datos['PACNACFEC'] = filter_dates(nuevos_datos['PACNACFEC'])\n",
    "nuevos_datos['CITAMBCREFEC'] = filter_dates(nuevos_datos['CITAMBCREFEC'])\n",
    "nuevos_datos['CITAMBPROCONFEC'] = filter_dates(nuevos_datos['CITAMBPROCONFEC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer solo la hora de la columna CITAMBHORCIT\n",
    "def extract_time_from_string(time_str):\n",
    "    try:\n",
    "        # Si es un objeto datetime, extraer la hora directamente\n",
    "        if isinstance(time_str, datetime):\n",
    "            return time_str.time()\n",
    "        # Si es una cadena de texto, procesarla\n",
    "        if ' ' in time_str:\n",
    "            time_str = time_str.split(' ')[1]\n",
    "        return datetime.strptime(time_str, '%H:%M:%S').time()\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "nuevos_datos['CITAMBHORCIT'] = nuevos_datos['CITAMBHORCIT'].apply(extract_time_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_datos['HORA_CITA'] = nuevos_datos['CITAMBHORCIT'].apply(lambda x: x.hour * 60 + x.minute if pd.notnull(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la edad del médico y del paciente\n",
    "nuevos_datos['EDAD_MEDICO'] = (pd.to_datetime('today') - nuevos_datos['MEDNACFEC']).dt.days // 365\n",
    "nuevos_datos['EDAD_PACIENTE'] = (pd.to_datetime('today') - nuevos_datos['PACNACFEC']).dt.days // 365\n",
    "\n",
    "# Calcular el tiempo entre la fecha de otorgamiento y la fecha de la cita\n",
    "nuevos_datos['DIAS_ENTRE_CITA'] = (nuevos_datos['CITAMBPROCONFEC'] - nuevos_datos['CITAMBCREFEC']).dt.days + 1\n",
    "\n",
    "# Calcular el precedente del paciente\n",
    "#nuevos_datos['NUM_CITAS'] = nuevos_datos.groupby('PERDOCIDENNUM')['PERDOCIDENNUM'].transform('count')\n",
    "#nuevos_datos['NUM_DESERCIONES'] = nuevos_datos.groupby('PERDOCIDENNUM')['ESTCITNOM'].transform(lambda x: (x == 'DESERCION').sum())\n",
    "nuevos_datos['TASA_DESERCION'] = nuevos_datos['NUM_DESERCIONES'] / nuevos_datos['NUM_CITAS']\n",
    "\n",
    "# Eliminar columnas originales que no serán necesarias\n",
    "nuevos_datos = nuevos_datos.drop(columns=['MEDNACFEC', 'PACNACFEC', 'CITAMBCREFEC', 'CITAMBPROCONFEC', 'CITAMBHORCIT', 'PERDOCIDENNUM'])\n",
    "\n",
    "# Verificar y manejar valores faltantes después de todas las transformaciones\n",
    "nuevos_datos = nuevos_datos.dropna()\n",
    "\n",
    "# Codificación One-Hot de variables categóricas\n",
    "nuevos_datos = pd.get_dummies(nuevos_datos, columns=['REDASISDES', 'CENASIDES', 'AREHOSDES', 'SERVHOSDES', 'ACTDES', 'GRUPOCUPNOM', 'CONDTRABNOM', 'TIPOCITANOM', 'CONDCITANOM', 'MODOTORCITANOM'])\n",
    "\n",
    "# Limpiar nombres de columnas\n",
    "nuevos_datos.columns = nuevos_datos.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X = nuevos_datos.drop(columns=['ESTCITNOM'])\n",
    "y = nuevos_datos['ESTCITNOM'].apply(lambda x: 1 if x == 'DESERCION' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1289756/3827877569.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  nuevos_datos_alineados = nuevos_datos_alineados.append(nuevos_datos, ignore_index=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- TIPOCITANOM_PROCEDIMIENTO\nFeature names seen at fit time, yet now missing:\n- CENASIDES_PMCONCHUCOS\n- CENASIDES_PMOYOTUN\n- GRUPOCUPNOM_ENFERMERAO\n- GRUPOCUPNOM_OTROS\n- GRUPOCUPNOM_PROFESIONAL\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb Celda 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Realizar las predicciones solo en las filas válidas\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mif\u001b[39;00m valid_mask\u001b[39m.\u001b[39many():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     prediccion_desercion[valid_mask] \u001b[39m=\u001b[39m modelo\u001b[39m.\u001b[39;49mpredict(nuevos_datos_alineados[valid_mask])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     probabilidades_desercion[valid_mask] \u001b[39m=\u001b[39m modelo\u001b[39m.\u001b[39mpredict_proba(nuevos_datos_alineados[valid_mask])[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Mostrar las probabilidades de deserción\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    516\u001b[0m ):\n\u001b[1;32m    517\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    581\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    582\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    502\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 506\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- TIPOCITANOM_PROCEDIMIENTO\nFeature names seen at fit time, yet now missing:\n- CENASIDES_PMCONCHUCOS\n- CENASIDES_PMOYOTUN\n- GRUPOCUPNOM_ENFERMERAO\n- GRUPOCUPNOM_OTROS\n- GRUPOCUPNOM_PROFESIONAL\n- ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtener los nombres de las características del conjunto de datos de entrenamiento\n",
    "train_feature_names = X.columns\n",
    "\n",
    "# Crear un DataFrame con las mismas columnas que el conjunto de datos de entrenamiento\n",
    "nuevos_datos_alineados = pd.DataFrame(columns=train_feature_names)\n",
    "\n",
    "# Añadir los nuevos datos al DataFrame alineado\n",
    "nuevos_datos_alineados = nuevos_datos_alineados.append(nuevos_datos, ignore_index=True)\n",
    "\n",
    "# Asegurarse de que todas las características faltantes se añadan con valor 0\n",
    "for feature in train_feature_names:\n",
    "    if feature not in nuevos_datos_alineados.columns:\n",
    "        nuevos_datos_alineados[feature] = False\n",
    "\n",
    "# Eliminar cualquier característica extra en nuevos_datos que no esté en train_feature_names\n",
    "nuevos_datos_alineados = nuevos_datos_alineados[train_feature_names]\n",
    "\n",
    "# Crear una máscara para identificar las filas válidas (sin valores nulos)\n",
    "valid_mask = nuevos_datos_alineados.notnull().all(axis=1)\n",
    "\n",
    "# Inicializar un array con NaN para las predicciones\n",
    "prediccion_desercion = np.full(len(nuevos_datos_alineados), np.nan)\n",
    "probabilidades_desercion = np.full(len(nuevos_datos_alineados), np.nan)\n",
    "\n",
    "# Realizar las predicciones solo en las filas válidas\n",
    "if valid_mask.any():\n",
    "    prediccion_desercion[valid_mask] = modelo.predict(nuevos_datos_alineados[valid_mask])\n",
    "    probabilidades_desercion[valid_mask] = modelo.predict_proba(nuevos_datos_alineados[valid_mask])[:, 1]\n",
    "\n",
    "# Mostrar las probabilidades de deserción\n",
    "print(probabilidades_desercion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- TIPOCITANOM_PROCEDIMIENTO\nFeature names seen at fit time, yet now missing:\n- CENASIDES_PMCONCHUCOS\n- CENASIDES_PMOYOTUN\n- GRUPOCUPNOM_ENFERMERAO\n- GRUPOCUPNOM_OTROS\n- GRUPOCUPNOM_PROFESIONAL\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb Celda 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Realizar las predicciones solo en las filas válidas\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m valid_mask\u001b[39m.\u001b[39many():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     prediccion_desercion[valid_mask] \u001b[39m=\u001b[39m modelo\u001b[39m.\u001b[39;49mpredict(nuevos_datos[valid_mask])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     probabilidades_desercion[valid_mask] \u001b[39m=\u001b[39m modelo\u001b[39m.\u001b[39mpredict_proba(nuevos_datos[valid_mask])[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ugadingenieria01/Documentos/GCTIC/DW_GCTIC/IA/test_model.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Mostrar las probabilidades de deserción\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    516\u001b[0m ):\n\u001b[1;32m    517\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    581\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    582\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    502\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    503\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 506\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- TIPOCITANOM_PROCEDIMIENTO\nFeature names seen at fit time, yet now missing:\n- CENASIDES_PMCONCHUCOS\n- CENASIDES_PMOYOTUN\n- GRUPOCUPNOM_ENFERMERAO\n- GRUPOCUPNOM_OTROS\n- GRUPOCUPNOM_PROFESIONAL\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Asegurarse de que las columnas en los nuevos datos coincidan con las de X_train/X_test\n",
    "for col in X.columns:\n",
    "    if col not in nuevos_datos.columns:\n",
    "        nuevos_datos[col] = 0\n",
    "\n",
    "nuevos_datos = nuevos_datos[X.columns]\n",
    "\n",
    "# Realizar las predicciones\n",
    "prediccion_desercion = modelo.predict(nuevos_datos)[:, 1]\n",
    "probabilidades_desercion = modelo.predict_proba(nuevos_datos)[:, 1]\n",
    "\n",
    "# Mostrar las probabilidades de deserción\n",
    "print(probabilidades_desercion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
